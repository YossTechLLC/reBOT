# Property Scraper Configuration Template
# Copy this file to .env and update with your actual values

# =============================================================================
# FILE CONFIGURATION
# =============================================================================

# Input/Output file names
INPUT_EXCEL_NAME=input_addresses.xlsx
OUTPUT_EXCEL_NAME=output_results.xlsx
DATABASE_NAME=scrape.db

# Excel configuration
ADDRESS_COLUMN=address
EXCEL_SHEET_NAME=Sheet1

# =============================================================================
# WEB SCRAPING CONFIGURATION
# =============================================================================

# Target website URL (REQUIRED - update this!)
TARGET_URL=https://example.com/search

# CSS Selectors for web elements (update based on target website)
SEARCH_INPUT_SELECTOR=input[name='search']
SEARCH_BUTTON_SELECTOR=button[type='submit']

# First result link selector (if FOLLOW_FIRST_RESULT=true)
FIRST_RESULT_SELECTOR=a.result-link:first-child

# =============================================================================
# BROWSER CONFIGURATION
# =============================================================================

# Headless mode (true/false) - set to false for debugging
HEADLESS_MODE=true

# Browser window size
BROWSER_WINDOW_SIZE=1920,1080

# Custom user agent (optional)
USER_AGENT=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36

# =============================================================================
# TIMEOUT CONFIGURATION
# =============================================================================

# Page load timeout in seconds
PAGE_LOAD_TIMEOUT=30

# Element wait timeout in seconds
ELEMENT_WAIT_TIMEOUT=10

# Database timeout in seconds
DB_TIMEOUT=30

# =============================================================================
# RATE LIMITING
# =============================================================================

# Delay between requests (in seconds) to avoid being blocked
MIN_DELAY_BETWEEN_REQUESTS=2.0
MAX_DELAY_BETWEEN_REQUESTS=5.0

# =============================================================================
# RETRY CONFIGURATION
# =============================================================================

# Maximum retry attempts for failed requests
MAX_RETRIES=3

# Delay between retries in seconds
RETRY_DELAY=5

# =============================================================================
# FEATURE FLAGS
# =============================================================================

# Save HTML snapshots for later re-parsing (true/false)
SAVE_HTML_SNAPSHOTS=true

# Follow first search result link (true/false)
FOLLOW_FIRST_RESULT=false

# Skip already processed addresses (true/false)
SKIP_PROCESSED_ADDRESSES=true

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# =============================================================================
# NOTES
# =============================================================================
#
# 1. CSS Selectors: Use browser DevTools to find correct selectors for your target website
# 2. Rate Limiting: Adjust delays based on website's rate limiting policies
# 3. Regex Patterns: For advanced extraction, modify patterns in config/settings.py
# 4. Headless Mode: Set to 'false' during development to see browser actions
#
